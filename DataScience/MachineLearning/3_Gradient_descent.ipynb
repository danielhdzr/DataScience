{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21faf0e-a383-455d-a71f-041a1ed307b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****** Gradiant descent (img 3.0) ******\n",
    "'''\n",
    "Busca Efficiency, optimization.\n",
    "*Upadating the weights of AI model.\n",
    "*Minimazing the training loss.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Por ejemplo: un avion que busca la forma mas optima o eficiente\n",
    "para llegar al punto de aterrizaje.\n",
    "'''\n",
    "\n",
    "\n",
    "# ****** Why not perceptron? (img 3.1) ******\n",
    "\n",
    "'''\n",
    "Perceptron regresa una prediccion o output binaria (0 o 1)\n",
    "mientras que Gradient descent regresa una prediccion decimal (0.65 por ejemplo)\n",
    "Esto la hace mas precisa\n",
    "'''\n",
    "\n",
    "# ****** 1.- Funcion de activacion o activation function (img 3.2) ******\n",
    "'''\n",
    "Definiremos una sigmoid function que regresa un output decimal (img 3.3).\n",
    "input*weight -> weighted sum+sigmoid -> decimal output\n",
    "\n",
    "(input by its weight == result, then sum all the results == weighted sum.\n",
    "weighted sum + sigmoid == decimal output)'''\n",
    "\n",
    "\n",
    "# ****** Formula sigmoid (img 3.4) ******\n",
    "'''\n",
    "1 / 1 + e ^ -w_sum\n",
    "(one divided by: one plus number 'e' in the power of minus the weighted sum)\n",
    "e == 2.71828\n",
    "'''\n",
    "\n",
    "# ****** 2.- Prediction  ******\n",
    "'''\n",
    "Definiremos nuestra prediction function mediante el nuevo modelo de weighted sum\n",
    "Weighted sum working example (img 3.5, 3.6)\n",
    "\n",
    "Formula para prediction (img 3.7)\n",
    "weighted sum = features * weights + bias\n",
    "(0.1*0.4) + (0.5*0.2) + (0.2*0.6) + 0.5 =\n",
    "0.04 + 0.1 + 0.12 + 0.5 = {0.76}\n",
    "'''\n",
    "\n",
    "# ****** Resultado Sigmoid (img 3.8) ******\n",
    "\n",
    "'''\n",
    "# 1 / 1 + e ^ -w_sum == 1 / 1 e ^-{0.76} = 1 / 1 + 0.46 = {0.68}\n",
    "# Prediccion o 'Y cap' (Y con ^ encima de la Y): {0.68}\n",
    "# No confundir con target (Y)\n",
    "'''\n",
    "\n",
    "# *** 3.- Passing the prediction into the Cross entropy loss function (img 3.9)\n",
    "'''\n",
    "Definiremos nuestra loss function\n",
    "***Cross Entropy Loss Formula***\n",
    "-(target * log(pred) + (1-target) * log(1-pred))\n",
    "\n",
    "-(0 * log(0.68) + (1-0) * log(1-0.68)) =\n",
    "-(1 * log(0.32)) = -(-0.49) = 0.49 } LOSS\n",
    "'''\n",
    "\n",
    "''' Updating the weights Formula (img 3.10) '''\n",
    "'''\n",
    "FEATURE[0]\n",
    "INDEX  |  [0]  [1]  [2]  TARGET       0\n",
    "X[i]   |  0.1  0.5  0.2  BIAS        0.5\n",
    "WEIGHT |  0.4  0.2  0.6  PREDICTION  0.68\n",
    "'''\n",
    "# New weight = old weight + learn rate * (target - pred) * x[i]\n",
    "# W' [i] = w[i] + a (alfa) * (Y-Y^) * x[i]\n",
    "\n",
    "# ***Learning rate is a very small floating point value. ex. 0.01, 0.001\n",
    "# Ensures a gradual weight update.\n",
    "# Often apears as a\n",
    "\n",
    "''' Updating bias Formula (img 3.11) '''\n",
    "'''\n",
    "FEATURE[0]\n",
    "INDEX  |  [0]  [1]  [2]  TARGET       0\n",
    "X[i]   |  0.1  0.5  0.2  BIAS        0.5\n",
    "WEIGHT |  0.4  0.2  0.6  PREDICTION  0.68\n",
    "'''\n",
    "# New bias = old bias + learn rate * (target - pred)\n",
    "# b = b + a * (Y-Y^)\n",
    "# Bias deja de ser el threshold, y se convierte en una constante que nos permite\n",
    "# perfeccionar nuestro modelo\n",
    "\n",
    "# ****** 4.- Updating weights (img 3.12) ******\n",
    "\n",
    "'''\n",
    "Los weights y el bias se actualizan para ser usados en la siguiente iteracion\n",
    "# es decir en el siguiente feature (feature[1] en este modelo)\n",
    "'''\n",
    "\n",
    "# ****** 5.- Updating bias (img 3.13) ******\n",
    "'''\n",
    "Como antes dije, los nuevos weights y bias sustituiran a los viejos tras\n",
    "cada iteracion (img 3.14)\n",
    "'''\n",
    "\n",
    "# Epoch (img 3.15)\n",
    "'''\n",
    "Una iteracion completa sobre nuestra tabla de features es un EPOCH\n",
    "En este ejemplo nuestra tabla consiste de 4 features\n",
    "4 features = 4 weight updates per Epoch\n",
    "'''\n",
    "\n",
    "# ****** 6.- Average loss (img 3.16) ******\n",
    "'''\n",
    "Se toma el loss (Cross Entropy Loss) de cada feature ([0], [1]... etc)\n",
    "y se divide entre el total de features\n",
    "If the average loss is increasing something is wrong,\n",
    "and must review the calculation (img 3.17)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
